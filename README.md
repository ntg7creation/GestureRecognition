# ğŸ–ï¸ 3D Hand Gesture Recognition and Control

This project integrates a 3D hand model rendered in Three.js with real-time hand gesture recognition using TensorFlow.js. Users can visualize hand gestures, control individual fingers using the keyboard, and send gesture labels to a Python Flask backend server.

---

## ğŸ”§ Features

- ğŸ§  Real-time hand gesture detection using **@tensorflow-models/handpose** and **fingerpose**
- âœ‹ Live overlay with emoji & finger pose information
- ğŸ® Keyboard-based control of 3D hand fingers (Q/W/E/R/G keys)
- ğŸ“¦ 3D hand model (`GLB`) rendered with **Three.js** and **OrbitControls**
- ğŸ” Communication with a Flask API for gesture validation

---

## ğŸ“ Project Structure

```
client/
  â”œâ”€â”€ App3.js              # Main React entry point
  â”œâ”€â”€ components/
  â”‚   â”œâ”€â”€ HandModelScene.jsx
  â”‚   â”œâ”€â”€ HandDetectionOverlay.jsx
  â”‚   â”œâ”€â”€ ThreeScene.js
  â”‚   â”œâ”€â”€ runHandposeDetection.js
  â”‚   â”œâ”€â”€ FingerController.js
  â”‚   â”œâ”€â”€ VisualOutput.js
  â”‚   â”œâ”€â”€ customGestures.js
  â”‚   â”œâ”€â”€ utilities.js
  â”‚   â””â”€â”€ api.js           # Communicates with Flask backend
  â”œâ”€â”€ App3.css             # Styling
  â””â”€â”€ index.js             # Entry point with <App3 />
server/
  â”œâ”€â”€ server.py            # Flask server
  â””â”€â”€ requirements.txt     # Backend dependencies
```

---

## ğŸš€ How to Run

### 1. Clone & Install

<<<<<<< HEAD
```
git clone https://github.com/ntg7creation/GestureRecognition/tree/python_server
cd your-repo
=======
>>>>>>> origin/python_server
```
git clone https://github.com/ntg7creation/GestureRecognition/tree/python_server
cd your-repo
```bash

bash

### 2. Install Frontend

```bash
cd client
npm install
```

### 3. Install Backend

```bash
cd server
pip install -r requirements.txt
```

---

### 4. Start Flask Server

```bash
cd server
python server.py
```

Server will start at `http://localhost:5000`

---

### 5. Start React Frontend

```bash
cd client
npm start
```

App runs at `http://localhost:3000`

---

## ğŸ–±ï¸ Controls

- `Q` â€“ pinky
- `W` â€“ ring
- `E` â€“ middle
- `R` â€“ index
- `G` â€“ thumb

Hold keys to flex fingers on the 3D hand model.

---

## âœ¨ Gesture Set

The system recognizes these gestures:

| Gesture Name  | Emoji | Description                     |
|---------------|-------|---------------------------------|
| `thumbs_up`   | ğŸ‘    | Only thumb extended             |
| `victory`     | âœŒï¸    | Index and middle extended       |
| `one_finger`  | â˜ï¸    | Only index extended             |
| `three_fingers` | ğŸ¤Ÿ | Index, middle, and ring extended |
| `four_fingers` | ğŸ––   | All except thumb extended       |
| `closed_hand` | âœŠ    | All fingers curled              |

---

## ğŸ§  Tech Stack

- **React + Three.js** â€“ front-end & 3D rendering
- **TensorFlow.js + fingerpose** â€“ hand pose detection
- **Flask** â€“ back-end API server

---

## ğŸ› ï¸ Future Improvements

- Add custom gestures via UI
- Integrate with VR/AR input devices
- Improve finger animation blending
- Use real camera instead of 3D render as input

---

## ğŸ“œ License

This project is licensed under the MIT License.---

### ğŸ™ Credits

- Gesture recognition base implementation adapted from [NickNochnack's Gesture Recognition repository](https://github.com/nicknochnack/GestureRecognition)
- 3D hand model by [TurboSquid: Low Poly Man Hand (3D Model)](https://www.turbosquid.com/3d-models/3d-low-poly-man-hand-2180828)